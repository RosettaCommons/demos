#
# This is a command file.
#
# To make a new test, all you have to do is:
#   1.  Make a new directory under tests/
#   2.  Put a file like this (named "command") into that directory.
#
# The contents of this file will be passed to the shell (Bash or SSH),
# so any legal shell commands can go in this file.
# Or comments like this one, for that matter.
#
# Variable substiution is done using Python's printf format,
# meaning you need a percent sign, the variable name in parentheses,
# and the letter 's' (for 'string').
#
# Available variables include:
#   workdir     the directory where test input files have been copied,
#               and where test output files should end up.
#   source      directory where Rosetta lives (Rosetta/main/source) (was minidir in older integration.py script, for example)
#   database    where the Rosetta database lives (Rosetta/main/database)
#   bin         where the Rosetta binaries live (Rosetta/main/source/bin)
#   binext      the extension on binary files, like ".linuxgccrelease"
#
# The most important thing is that the test execute in the right directory.
# This is especially true when we're using SSH to execute on other hosts.
# All command files should start with this line:
#

cd %(workdir)s

[ -e %(bin)s/match.%(binext)s ] || exit 1
%(bin)s/match.%(binext)s -database %(database)s @rosetta_inputs/general_match.flags @rosetta_inputs/1tml_sys.flags  2>&1 \
    | egrep -vf ../../ignore_list \
    > log

echo "Finished running the matcher, now running design."

[ -x %(bin)s/enzyme_design.%(binext)s ] || exit 1
%(bin)s/enzyme_design.%(binext)s -database %(database)s @rosetta_inputs/general_design.flags -s rosetta_inputs/UM_1_D41H116K189_1tml_11_mocktim_1.pdb -out:file:o scorefile.txt  2>&1 \
    | egrep -vf ../../ignore_list \
    >> log

echo "Finished running design, now running DesignSelect"

[ -e %(source)s/src/apps/public/enzdes/DesignSelect.pl ] || exit 1
perl %(source)s/src/apps/public/enzdes/DesignSelect.pl -d rosetta_inputs/mocktim_all_design_scores.out -c rosetta_inputs/mocktim_design_selectreqs.txt > selected_designs.txt  2>&1 \
    | egrep -vf ../../ignore_list \
    >> log

test "${PIPESTATUS[0]}" != '0' && exit 1 || true  # Check if the first executable in pipe line return error and exit with error code if so


#
# After that, do whatever you want.
# Files will be diffed verbatim, so if you want to log output and compare it,
# you'll need to filter out lines that change randomly (e.g. timings).
# Prefixing your tests with "nice" is probably good form as well.
# Don't forget to use -constant_seed -nodelay  so results are reproducible.
# Here's a typical test for a Mini binary, assuming there's a "flags" file
# in this directory too:
#
## %(bin)s/MY_MINI_PROGRAM.%(binext)s @flags -database %(database)s -run:constant_seed -nodelay  2>&1 \
##     | egrep -v 'Finished.+in [0-9]+ seconds.' \
##     | egrep -v 'Dunbrack library took .+ seconds to load' \
##     > log
#
# Or if you don't care whether the logging output changes:
#
## %(bin)s/MY_MINI_PROGRAM.%(binext)s @flags -database %(database)s -run:constant_seed -nodelay  2>&1 \
##     > /dev/null
#
